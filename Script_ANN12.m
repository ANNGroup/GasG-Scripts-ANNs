% Name of code: Script_ANN12
% Developer and contact address: A. Acevedo-Anicasio and Instituto de 
% Energias Renovables, Universidad Nacional Autonoma de Mexico; Priv. 
% Xochicalco s/n, Temixco, 62580
% Morelos, Mexico
% Telephone number: Tel.: +52 (55) 5622-9774, Fax: +52 (55)5622-9791
% e-mail: esg@ier.unam.mx

% Year first available: 2018
% Suggested hardware: Intel Core Processor i5-2300, 2.80GHz, Ram Memory 
% 4 GB, and  a Hard drive 500 GB
% Software requirements: Matlab for Windows v. R2017b (MathWorks, 2017)
% Programming language: MATLAB
% Programming file size: 49 kB with 386 lines of code

clear all
close all
clc

%target: BHT (°C) 
t = [239	250	289	296	305	295	275	275	270	285	320	280	295	290	280	305	320	327	325	330	330	330	324	340	290	300	300	300	170	170	225	320	240	300	300	325	295	300	215	247	299	182	215	225	290	280	320	240	240	278	306	250	250	260	260	240	260	260	270	250	250	240	240	240	250	250	230	260	240	250	240	240	250	240	240	250	250	260	250	240	270	212	246	238	205	217	215	338	343	325	325	281	281	281	293	293	293	304	304	304	279	279	300	300	300	292	292	292	296	296	296	280	280	280	306	306	306	287	287	287	314	314	315	315	267	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	287	287	287	287	287	287	287	287	287	287	287	287	287	287	287	287	287	287	271	271	271	271	271	271	271	271	277	277	277	277	277	277	277	302	302	302	302	302	302	302	302	302	248	248	278	278	278	278	302	302	302	302	302	302	302	302	302	280	265	265	265	265	265	265	265	265	265	265	265	276	276	276	276	276	276	267	267	267	267	267	267	267	334	334	262	262	278	274	274	274	274	274	352	352	311	311	311	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	301	301	281	327	327	329	329	329	329	329	329	329	329	329	329	329	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	384	384	384	384	356	356	356	356	268	319	319	319	319	319	267	267	267	267	262	262	262	330	330	363	304	300	350	290	322	322	322	322	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	284	284	284	284	307	307];
    
%inputs: ln(CO2), ln(H2S), ln(CH4), ln(H2) mmol/mol
p = [5.9864520053	8.0727793332	7.6333696497	6.9565454432	6.6720329455	7.0983756386	6.5219261454	6.7400643334	6.7190644444	6.0860342604	5.9817049716	6.4863217677	6.1126054869	6.1089690700	6.4964431008	6.3291029310	6.7813022227	6.7138309735	6.6574811520	6.7207836672	6.4768723679	6.7682163269	6.7226210536	6.6904141291	6.6292634052	6.8439045892	6.8334722537	6.8243517721	6.5680539117	6.6334066004	6.6332357248	6.6186408994	6.4068947674	6.5967340594	6.6327957390	6.6942300686	6.6672685036	6.7401922489	6.7464586998	6.5615024572	6.4321673338	6.7572894181	6.5228390436	6.5769050692	6.2598527372	6.2224890719	5.7403391279	6.8440497794	6.8161532856	6.6862770070	5.7917933520	6.8471556569	6.8453478189	6.8647433884	6.8411880347	6.8633853312	6.8450284491	6.8433234188	6.8335703808	6.8381908156	6.8743019027	6.8802813020	6.8806923594	6.8779144370	6.8878586473	6.8884705176	6.8795615446	6.8586700713	6.8800757099	6.8433234188	6.8652652274	6.8467305771	6.8446024640	6.8609780874	6.8561461452	6.8589851146	6.8726461019	6.8409742453	6.8499142793	6.8328161923	6.8512907420	6.7464121286	6.5161930760	6.7226297949	6.6293632534	6.7417006947	6.5764695690	6.7611001532	6.8070121486	6.7184091073	6.7068623366	6.5694814204	6.7787848977	6.7437057670	6.7062509028	6.7776465936	6.7469995001	6.7776465936	6.7116187332	6.7493455422	6.7696419769	6.7791261364	6.7181673862	6.7707894239	6.7457068270	6.7383894333	6.7569323892	6.6956753000	6.7742238864	6.7392182772	6.7156257812	6.7145345413	6.7178046950	6.6954280201	6.8145428973	6.6694980899	6.7133206543	6.7607622552	6.7742238864	6.7031881132	6.7317338347	6.7345916600	6.7440591863	6.7382709710	6.8916258971	6.8721281013	6.8936563546	6.8936563546	6.8663497809	6.8605169102	6.8824374710	6.8573857683	6.8592391773	6.8783264683	6.8783264683	6.8789441971	6.8824374710	6.8762646119	6.8741984955	6.8737847594	6.8679744090	6.8710912946	6.8721281013	6.8721281013	6.8689448017	6.8750254544	6.8658910749	6.8658910749	6.7960289892	6.8525994401	6.8363849407	6.8211074723	6.7867169506	6.7765069924	6.8885724596	6.7765069924	6.6982680541	6.8012830345	6.8638033915	6.7855876450	6.6656837178	6.8881646292	6.8881646292	6.7765069924	6.6982680541	6.7058838629	6.7056390949	6.1225564040	6.8936563546	6.8930476501	6.8948203493	6.8936563546	6.8977352457	6.8980079275	6.8977049431	6.8932658118	6.8875525717	6.8308742346	6.8679744090	6.7817089461	6.7634229081	6.7638849086	6.6594434415	6.8725663473	6.8861229789	6.8865316425	6.8697418368	6.8307652252	6.8700534118	6.8700534118	6.8703648898	6.8703648898	6.8310370634	6.8470632174	6.8961983313	6.8948523936	6.8894894702	6.8895913084	6.8936563546	6.8330317328	6.7781464687	6.8469431396	6.7416763307	6.8426832822	6.7718210017	6.7719355558	6.7341040262	6.0150419039	6.8942646888	6.8942646888	6.8942646888	6.8946700394	6.8677414503	6.8680056260	6.8841836379	6.8810005417	6.8403539974	6.8429767290	6.8488859907	6.8645539153	6.8569702764	6.8824374710	6.8826425782	6.8826425782	6.8654738867	6.8844805108	6.8918291284	6.8742100167	6.8881646292	6.8881646292	6.8885724596	6.8802813020	6.6525056144	6.6777809509	6.8779441713	6.8712209543	6.4103574311	6.8844866520	6.8762646119	6.8821297313	6.8452392446	6.8142567669	6.8689607934	6.8629670962	6.8796643988	6.6345035481	6.7708467617	6.8802967197	6.8956826977	6.8956826977	6.8802272994	6.8844866520	6.8730613445	6.8744518243	6.8793794667	6.8916258971	6.8824374710	6.8824374710	6.8834625864	6.8837361146	6.8857141481	6.8843157060	6.8772960715	6.8772960715	6.8799728980	6.8803840822	6.8783264683	6.8814113036	6.8803840822	6.8762646119	6.8046499962	6.8536179441	6.8119278436	6.8620928941	6.7682724007	6.8346070000	6.8503909616	6.8171082100	6.8243736700	6.8399046121	6.8244823598	6.8244823598	6.7822816212	6.7558573930	6.6523132008	6.8518661769	6.8707115545	6.8764721211	6.8764954127	6.8853005842	6.8250777242	6.8976501928	6.9019173235	6.8880213589	6.8899559091	6.8910892349	6.8963761756	6.8948679851	6.8951109400	6.8961448352	6.8927897508	6.8882004196	6.8884537665	6.8610694980	6.8799803709	6.8896399358	6.8924057824	6.8896931362	6.8992639167	6.8962432387	6.8915394511	6.8958961109	6.8906556393	6.8934510355	6.8893667759	6.8697418368	6.8697418368	6.8997523957	6.8915448226	6.8939578861	6.8931266903	6.8813312983	6.8993995725	6.8866328120	6.8787559767	6.8871833852	6.8845917473	6.8557048330	6.8880567312	6.8829301040	6.8976892366	6.8812164475	6.8815996707	6.9016821012	6.8761775974	6.8848459436	6.8875935117	6.8877356328	6.8565161344	6.8782713880	6.8821427656	6.8923457143	6.8671519310	6.8866541897	6.8801165419	6.8755205961	6.8690144507	6.8802390428	6.8717658818	6.8965269260	6.8915908649	6.8516963891	6.8467254171	6.6466637412	6.8331676883	6.8218770189	6.8622347637	6.8622347637	6.8068293604	6.7916394365	6.8090393060	6.8176117291	6.8176117291	6.6572739368	6.7289230245	6.7159892634	6.6093492432	6.7600670061	6.7382709710	6.8302205628	6.7696419769	6.8036162392	6.8036162392	6.8448154792	6.8707800429	6.8707800429	6.8068293604	6.7620521332	6.5493361023	6.6623748766	6.7238816419	6.7791232751	6.6567133923	6.7810718521	6.7801491544	6.7801491544	6.7776465936	6.8510887454	6.7916341954	6.7965469223	6.7832489971	6.8769646450	6.8409151817	6.8395820990	6.8618728966	6.8297256642	6.8134029622	6.8329261863	6.8147919304	6.8308238267	6.8592112270	6.8351711300	6.8160148968	6.8161907217	6.7975833989	6.8328307783	6.7055073805	6.7968897693	6.8385347400	6.8413877525	6.8133509818	6.8129733021	6.8143892205	6.8382026953	6.8149295836	6.8250180104	6.8057084005	6.8129713678	6.7856651964	6.8453773431	6.8265683099	6.7419596273	6.8084016017	6.8275665067	6.8376161072	6.8279798435	6.7957011238	6.8211074723	6.8423705961	6.8206708346	6.7526934401	6.8022417854	6.8030506576	6.8036494903	6.8342093812	6.7450186355	6.8200112623	6.7884640411	6.8370564665	6.7764988321	6.7935938579	6.8228657529	6.7993517256	6.7603508850	6.8232598738	6.7728697405	6.8144105453	6.7915495668	6.8188851950	6.8271960467	6.8416976933	6.8284577420	6.7719098040	6.8353966378	6.8652532029	6.8129909920	6.8110869447	6.8202444187	6.8385275915	6.8134761371	6.8243953549	6.8543492350	6.8054257293	6.8399746829	6.8309771246	6.7622903249	6.8372778703	6.7933694431	6.8305905599	6.8108501260	6.8210503033	6.8266835493	6.7938675831	6.8314732079	6.8229398300	6.6625150573	6.8169999565	6.8039462587	6.8274358873	6.8098730292	6.7864071868	6.8236329527	6.8244536312	6.8265775427	6.8491894117	6.7982718806	6.8057204081	6.8288202909	6.8288202909	6.7227938523	6.7942083471	6.8181099243	6.7896566813	6.7724076171	6.8255063747	6.8194718119	6.7805244643	6.8251961028	6.8003610588	6.7498384065	6.8193258111	6.8069691004	6.7342011810	6.78422354	6.802169933	6.800406135	6.796387479	6.829436441	6.807594657	6.825210062	6.8109955	6.800137571	6.802885414	6.796578812	6.787556103	6.820917929	6.800860506	6.797841494	6.708956326	6.658350824	6.667743928	6.853822559	6.850126166	6.851819647	6.851819647	6.774223886	6.63046282
3.5085559000	3.9239515763	4.2710950740	4.8675344505	5.2832037287	2.3025850930	5.3915651584	4.1713998013	4.6292601156	5.8770990551	5.7479979417	5.2157963429	5.6635921336	5.6873575950	5.2210494357	5.6178064320	4.3387959390	4.5877023179	4.5582369830	4.4276177961	3.6762006769	4.2017733172	4.4426987320	4.7932941442	4.6876916577	3.6118268924	3.7469292455	3.7211992500	4.7535661914	4.8985031562	4.5571782811	4.6525280431	3.1643024159	4.2316286094	2.4564072678	3.8051707699	1.2865485786	4.1914962416	4.6772100228	3.9304132972	5.2389964625	4.7749655579	3.4760093903	4.1293885795	5.3135712917	5.2435627690	5.3513045612	2.6603611721	3.4660882584	4.9713553199	5.4372521672	2.9496883351	3.0056826044	2.6246685922	2.6946271808	2.6173958328	2.9806186357	2.9856819377	3.2503744919	3.1527360224	2.3025850930	2.1633230257	2.1517622033	2.3795461341	1.6292405397	1.5260563035	2.3321438952	3.0056826044	2.2192034841	2.9907197317	2.3025850930	3.0106208860	3.0397491590	2.5572273114	2.8791984573	2.7408400239	2.2823823857	3.1267605360	2.8273136219	3.1179499063	2.9123506646	4.0073331852	3.7135720667	4.7004803658	4.2484952420	4.4998096703	4.0775374439	4.5029668228	2.0082208506	4.0809215419	3.9740583963	4.0412953411	3.8649313979	4.0587173846	3.9100210028	3.6428355156	3.5918177413	3.8628327612	4.3707128748	3.9871304779	3.9569963711	3.4563166809	4.2584455729	3.8958936235	4.0412953411	4.2031989671	3.9871304779	4.4224485492	3.8753590211	4.0199801469	4.0604430105	4.0621656639	4.0876555741	4.0535225677	3.2695689392	3.9259259106	3.9627161197	3.8088822465	3.8794998137	4.1174098352	4.0199801469	4.0483006237	3.9239515763	3.9945242269	2.2721258855	3.2228678461	2.2300144002	2.2300144002	3.3499040873	3.4460113975	2.9444389792	3.3882134541	3.4573256354	3.1267605360	3.1267605360	3.0445224377	2.8332133441	3.0910424534	3.1654750481	3.1642084235	3.4011973817	3.1654750481	3.2884018875	3.2884018875	3.3069965863	3.0019628233	3.2695689392	3.2695689392	3.3792925463	3.3205295075	2.3105532626	1.1314021115	2.2407096893	2.2407096893	2.2823823857	2.2925347571	1.9600947840	2.0412203289	1.5260563035	1.9315214116	2.3321438952	2.2803394840	2.2803394840	2.3025850930	1.9600947840	2.0554049639	2.0541237337	2.4023399261	1.6677068206	1.7698546338	1.7639547766	1.9021075264	1.7732559977	1.7732559977	1.7749523509	1.9216174565	2.7146947438	4.1557531904	3.2733640102	4.2130308935	4.5617406281	4.5622626850	4.6654478554	2.8745810720	2.7245795031	2.7278528284	3.2308043957	3.3307072899	2.9704144656	3.1986731176	3.1986731176	3.1986731176	3.4897674433	3.3263660710	1.2947992198	1.7021993925	2.1552445051	2.1517622033	2.2300144002	3.8794998137	4.1980887724	3.6428355156	4.1762704433	3.2995337279	4.4242476501	4.4236483094	4.5663565900	3.1786369936	2.0333976032	2.0333976032	2.0333976032	2.0281482473	2.1823404451	2.1860512767	2.1951112347	2.3155013183	2.1972245773	2.3263016196	2.9704144656	3.1229192774	2.9356106502	2.5257286443	2.5273273657	2.5273273657	3.1341890167	2.4725810001	2.2690283095	2.3934953984	2.4248027257	2.4248027257	2.4248027257	2.8355635214	4.4288648188	4.6177210928	3.0155793116	3.1851949385	3.4973859634	2.3795461341	3.2148678035	1.9416152248	2.8798723875	2.7957424990	3.1803385185	3.3703944725	2.7972813348	4.6798333706	4.4176229993	2.8693183487	1.9600947840	1.9600947840	2.8618740732	2.7725887222	2.9357699324	2.9667667953	2.7725887222	2.2300144002	2.8449093838	2.8678989020	2.8213788864	2.7380619752	2.6810215287	2.6780719776	2.9704144656	2.9704144656	2.8213788864	2.8213788864	2.9957322736	2.7725887222	2.8449093838	2.8094026954	2.5504602805	3.5528592527	3.9222724618	3.2624876254	4.4589858807	3.1496972218	3.7605021978	4.1728476237	4.1319614258	3.8159525367	4.1319614258	4.1319614258	4.3095097038	4.1344462974	4.0562099257	3.4515735890	3.0253396183	2.4611006045	2.4599579229	2.6240393520	4.2818310749	0.2422842998	1.0437539712	2.7481801425	2.4594731651	2.4483368611	0.5597515909	0.4487047185	2.0101680128	1.8612723167	2.1084041528	2.8249854045	2.8082008272	2.9977026036	3.0463162437	2.3866987326	1.8090597096	2.3887627892	-0.3035385898	1.7138719333	2.1074566847	1.6306453604	2.3463228161	1.4461854002	1.9111173458	3.3843902633	3.3843902633	0.9215632234	1.9221327009	1.9758390589	1.8807756971	2.9491798796	0.1255476562	2.5423266391	2.6158128725	2.2558970480	2.7329162904	3.5902741954	2.4663428787	2.4751672658	1.0589500126	2.6587575368	2.8726616275	-2.2714695825	3.1368372434	2.3931713719	2.5189706824	2.3967798258	3.4138184033	2.9178147882	2.1723272680	1.2015049362	3.4195036948	2.0550439066	1.3030943042	2.2598762656	2.3978952728	2.6226575413	2.3726238225	-0.3117109235	0.4206305442	3.6046932271	3.5189570173	4.9673432642	3.7028238251	3.8630438293	3.5765502691	3.5765502691	4.2484952420	3.8246700232	3.9318256327	4.0315822405	4.0315822405	4.8932566027	4.6447486255	4.5753293440	5.1704839950	4.5228749433	4.6563384726	3.6615506408	4.1896547420	4.1507248957	4.1507248957	3.6375861597	3.2538567938	3.2538567938	4.1108738642	4.3116903188	4.9472169560	4.2877899003	4.4726656545	4.4776248469	4.9583016271	4.3506063856	4.4169110365	4.4169110365	4.2766661190	3.9139508356	4.5501774084	4.4618859281	4.1683343523	3.1104629927	3.9228058440	4.0567686056	3.5141022147	4.2131530966	4.3570617031	3.9273185557	4.2751743599	4.1560844676	3.4669761110	3.9691861779	4.2136376209	4.1787266980	4.5077470940	3.9992384550	5.1143980461	4.3375599613	3.9500913528	3.5604936863	4.2506015095	4.2523240559	4.2442621626	3.9410813104	4.3310356962	4.1385968593	4.3504250975	4.2422208395	4.5355590515	3.8129340081	4.0241266245	4.8917518709	4.3020745519	4.0102182058	3.9474977692	4.1091288624	4.4190932455	4.1108738642	3.9214554601	4.1146886032	4.8490210276	4.3217574860	4.3141673559	4.3060334585	3.9001983378	4.8518512729	4.0740212270	4.4864228107	3.9057316455	4.5243562110	4.4372246595	4.1495496864	4.3448109727	4.4883372618	4.1384326912	4.6004904073	4.0646425633	4.4412571467	4.1211664734	4.0711411366	3.8752088737	3.9719543009	4.6978392580	3.9647058317	2.8204913906	4.0643925386	4.1614388282	3.9114675987	3.8555813276	4.2538373269	4.1873841384	3.3830264029	4.2529093130	3.8775683478	4.0216569682	4.7679800057	3.9309763020	4.3331764499	3.9751391483	4.1826722046	3.9979423084	4.0303356436	4.2861963899	3.8188514696	4.1405148966	5.2609234768	4.1794639252	4.3158358108	4.0321945941	4.2338301857	4.3417490161	4.1040529962	3.8962711749	4.0027282517	3.6274511166	4.2194966261	4.3028775089	4.0631978332	4.0631978332	4.9642261355	3.9762981710	4.0475568953	4.2789861734	4.5804359202	4.0300788370	3.9873112103	3.9005906806	4.0249436066	3.7843171008	4.7813532792	3.9926121230	4.2332633277	4.5879647792	4.478182852	4.264057093	4.352616196	4.077093904	3.887546407	4.153541177	3.900052242	4.154344925	4.1756237	4.29663649	4.356004098	4.441724181	3.956487007	4.292690353	4.140446832	4.467006071	4.345672596	4.294387642	3.400517804	3.583518938	3.718438256	3.718438256	4.49980967	4.797289352
-0.5108256238	1.5892352051	-0.0010005003	0.9555114450	0.9932517730	1.0986122887	1.2644307734	1.7670320140	-0.0404485915	1.1342394663	-1.0588314187	0.6831968497	0.9421214919	0.4880109460	1.3575534712	0.4137997449	-0.0065491290	-1.2288207797	-1.1024860022	-0.7810874117	-1.0217512425	-1.0230768975	-0.3421379742	-1.9546124338	1.1899333143	-1.0919538065	-1.0938070118	-0.7604768626	2.8376499692	1.1541272966	2.6177336719	0.3585704269	1.3661223789	2.6358072469	0.7698520520	-0.0189278410	-0.1243312580	0.5784639913	1.7347091995	1.9916994150	-1.0484489599	0.6554768139	0.1257320991	0.4338645826	1.0861636112	3.2588090220	-0.0589307215	-0.7188573029	-0.3708442956	-0.0454623741	1.0760649144	2.6532419646	2.5802168296	1.9315214116	2.9601050959	2.1747517215	2.7212954279	2.7212954279	2.6246685922	2.5257286443	1.4586150227	1.2809338455	1.1939224685	1.1631508098	0.9555114450	1.0986122887	0.6418538862	1.4350845253	1.0986122887	2.6173958328	2.4849066498	2.3223877203	2.1633230257	2.2721258855	2.1162555148	2.2721258855	1.8562979904	2.4069451083	2.4595888418	2.8213788864	2.1972245773	2.0794415417	1.9459101491	2.4849066498	2.1972245773	2.0412203289	1.6292405397	0.6743254263	1.9617008350	3.6082115510	3.7909846771	3.7518542533	3.4404180948	3.6349511121	3.8836235309	3.2921262866	3.6888794541	3.4144426084	3.6838669123	3.6988297850	3.2268439945	3.3843902633	3.5234150144	3.4995332824	3.7160081215	3.6913763343	3.4436180975	3.7518542533	3.3357695763	3.6054978452	3.7184382564	3.9318256327	3.8586222287	3.9278963546	3.0301337003	3.8177123260	4.0395363257	3.7588718259	3.6136169696	3.7909846771	3.7635229971	3.7062280924	3.5322256441	3.6163087613	-1.4696759701	-0.3285040670	-1.2378743560	-1.2378743560	0.2538667240	0.3763795272	-0.5447271754	0.4485245976	0.1722712209	-0.7339691751	-0.7339691751	-0.5798184953	-0.4620354596	0.0953101798	-0.5621189182	-0.5709295478	-1.0216512475	-0.7985076962	-1.1394342832	-1.1394342832	-0.3147107448	-0.1086994169	0.0953101798	0.1310282624	0.4356709502	0.4603643831	-1.6766466621	-2.3025850930	-1.6607312068	-1.6607312068	-1.9661128564	-2.5257286443	-0.3011050928	-1.2378743560	-1.4696759701	-0.8675005677	-0.8915981193	-1.9951003932	-1.9951003932	-2.5257286443	-0.3011050928	-1.7372712839	-1.7147984281	-6.9077552790	-0.7550225843	-1.1270117632	0.0473532275	-0.8675005677	-2.3751557858	-2.3751557858	-2.4079456087	0.1806534997	-3.2188758249	-0.0512932944	-0.2231435513	-0.8051966844	-1.4439234740	-1.4271163556	0.9399208094	-0.2770718933	-3.4737680745	-3.5065578973	-0.2156715365	-0.4112098777	-0.8209805521	-1.9661128564	-1.9379419794	-1.9379419794	0.6489421262	-2.5257286443	0.5550163697	0.5288619863	-0.0120725812	-0.0100503359	-2.4079456087	1.0986122887	-1.3394107752	-2.4079456087	-0.7187811411	0.1823215568	-0.9263410677	-0.9162907319	-0.4323225623	-6.9077552790	-0.4942963218	-0.4942963218	-0.4942963218	-0.4942963218	-0.4668545129	-0.4636240223	-0.0222456089	0.2143046026	-0.8324092479	-0.0366639844	-2.7806208939	-0.2868999784	-0.1827216368	-0.5447271754	-0.5464528014	-0.5464528014	-0.2045671657	0.2866815721	-1.4653375685	-0.9346866540	-2.3330443005	-2.3330443005	-2.3025850930	-0.6443570164	0.3058573469	-0.5412848313	-0.0445654509	-0.0242926926	-3.0576076773	-1.8971199849	-0.0010005003	-2.3751557858	-6.9077552790	-2.5048040976	-0.3702883299	-0.4307829161	-0.9038682119	0.7953115440	-0.5942072327	-0.6124892775	-1.0498221245	-1.0498221245	-0.1487449339	-0.3424903089	0.7352483566	-0.2407984866	-0.3038114544	-0.5276327421	-0.7133498879	-0.7133498879	0.0953101798	-0.4124897230	-0.3229638866	-0.0356271776	-0.1053605157	-0.1053605157	-0.2757535016	-0.2744368457	-0.4004775666	-0.0725706928	-0.4620354596	0.1484200051	0.2199384204	-0.7808860949	1.1760561145	-0.3887507741	0.8089907812	-0.6812186097	-0.7052197618	0.4774756441	-0.9675840263	-0.1031407589	-0.9545119447	-0.9545119447	-0.5923972775	0.2926696140	-0.6236211179	0.1906203596	0.2191355299	-1.4126104108	-1.3560859484	-2.9072554077	-2.5496606884	0.4952808143	-1.0703731285	-1.1652866087	0.4525805057	0.1394471750	0.5280028926	-0.5242322633	-3.0684600373	-0.7663506353	-1.8588260463	-0.8264364871	-2.0449480746	-3.9703806640	0.1524453876	0.4418211082	-0.5464821104	0.4446858213	-0.6483790761	-0.6569795510	-0.6558007101	-0.2100783388	-0.6549667425	0.4952091104	0.0113055693	-0.5225608800	-0.5225608800	-0.2654600226	-0.5852040852	-0.7651125784	-0.9257145768	-0.2212418591	0.1631827598	-0.1111779863	-0.5756955523	0.1818174494	-4.8056934902	0.0239228366	-2.9078456106	-0.6971916047	-3.0111375720	-2.2997555465	0.0557397987	-2.1155347809	-2.3510582007	-3.1329843903	-2.7232410477	0.1618042491	-0.2792539290	-0.7307133704	-0.6241599216	0.7199288116	-0.7378742457	-3.5076923789	-0.9182468798	-0.9448313783	-0.5798184953	-0.7047941306	-0.5720532803	0.5098834752	-0.0493730851	0.3314567950	1.3527083678	1.9671248704	-0.6248087375	1.2309099497	-0.2823629110	-0.2823629110	1.2725655958	3.0305456975	3.0973859273	1.7852382522	1.7852382522	1.5106397286	3.0232810571	3.4858142274	3.4544221429	2.9977302762	3.0351452759	1.8900637229	3.4108176250	1.5027431738	1.5027431738	-0.3856624808	-2.6592600369	-2.6592600369	2.3978952728	3.1641948408	-0.2355209614	3.9027698871	3.5416130234	-0.0532680851	3.0200834181	2.6647280839	0.9030028375	0.9030028375	1.4279160358	-5.9107481245	-2.7892606374	1.1180827463	-2.7983022579	-3.1331326426	0.7008024873	0.0512195422	0.6809727416	-9.7334795368	1.2084568771	1.1442271113	-0.8257919254	-0.1813178866	-1.2453742262	-3.0859146717	-0.6619320162	1.0849536861	0.1706939574	-1.9309067846	0.5032887186	-0.3321487458	0.0766512849	-1.8277719169	-0.4058191208	-0.4239655903	-2.8336194001	0.1450610545	0.3900008474	0.1863227353	-2.7076145734	-0.2835322253	0.5777274785	-0.0618345694	-1.6889898170	0.6171219208	0.6320548204	0.6309910411	-0.2640481469	-0.4901913487	0.4216261314	1.2809338455	0.2299405426	1.2851057246	-0.2949005115	0.7520441554	1.0829671532	-1.8345269977	0.7094088984	0.9679856991	1.2287699044	0.6859500068	-1.4922018770	-1.6878961737	-2.4647788154	0.2740245613	0.5104117614	-7.6543291190	0.4728022224	-1.6870244619	-1.0015395407	1.3004991011	0.5484490593	-0.2083412472	-0.2039034964	0.9117585726	1.0510986960	-0.5044521728	0.4626433232	-1.4982264517	-1.0999704431	0.7557195259	0.0646929308	-0.0270051330	-0.7268074361	-1.4535023157	1.2324065768	0.6113732031	-0.0519597259	0.3876329344	-0.3947721202	1.5683354145	0.6339048021	1.3371220802	-0.9428939876	0.4670261827	0.5928549411	0.1160635855	0.2156943929	1.7855807142	0.0291130230	0.4025993494	0.7900281047	0.3253821181	0.3123821660	-1.6714431291	-0.9009767428	-0.6793348719	0.5055296208	0.0578599843	0.0518068576	-0.9364934392	-0.9364934392	0.6938033569	-2.8966858650	2.1273969444	1.9695045013	0.4935828866	0.3572347149	0.0836443981	-0.0473624381	0.1202301642	0.1340909427	-0.1871945863	-1.1466405489	0.2474182587	1.0031020275	0.859995684	1.911690491	-0.450533074	-0.368360758	-0.491919406	0.239559307	0.882879637	-0.738507333	-0.346449008	-0.496805121	-0.586038405	-0.642234463	-0.248190731	-0.545203021	-0.64704491	-4.358363622	-2.204949269	0.769747441	-1.051739962	1.134622726	-0.783071888	-0.783071888	3.253083996	3.354453079
1.1314021115	2.6602595373	1.9315214116	2.8903717579	2.8154087194	2.8903717579	3.6623260462	1.6735059560	4.1158269285	5.0744333487	5.2583332681	4.7830815923	5.2094852183	5.2690717985	4.6572813927	5.0122809427	3.6196732720	4.3049102307	4.7203558325	4.3990897125	4.5746109835	4.1443510859	4.4223642504	4.2229543929	4.8054746934	3.1980904385	3.2524305150	3.5861940177	4.1525894706	4.5895160430	0.9462603685	4.8488603369	2.2480116841	3.8886838582	2.9964882497	4.0532948042	3.7050101290	4.0267288838	1.2812896982	4.5896589261	5.1617047882	2.9284614371	2.8194963430	2.5700014680	5.5630625654	5.5685626045	6.1675366020	0.4631365947	-0.6946313727	2.7415566130	6.0407229857	2.9755295662	3.0252910758	2.7278528284	2.8678989020	2.6532419646	2.8735646396	2.8449093838	3.2148678035	3.1780538303	2.7788192720	2.5952547070	2.5726122302	2.6390573296	2.3702437415	2.2823823857	2.7013612130	3.0955776085	2.6246685922	2.9956822723	2.3223877203	3.1398326175	3.3250360207	2.8273136219	2.9755295662	2.8390784635	2.6672282066	3.2425923515	3.0349529867	3.2228678461	3.1045866785	-0.9162907319	-0.1053605157	-0.1053605157	0.6931471806	-0.5108256238	-0.0010005003	3.2000540706	0.5266163097	3.9550824949	4.1494638614	2.8735646396	3.0056826044	3.0397491590	3.8110970868	3.8501476017	4.1805222585	3.2188758249	3.3534067178	3.4657359028	3.6082115510	3.6813511877	3.1135153092	3.2809112158	3.4499875458	3.2809112158	3.5496173868	3.7111300630	3.3463891452	3.6506582413	3.7232808808	3.8242840911	3.8649313979	4.0000338828	3.0955776085	3.5496173868	3.7160081215	2.8903717579	2.9444389792	3.1090609589	3.6375861597	3.6661224670	3.6609942506	3.7841896339	0.7884573604	0.5877866649	0.8329091229	0.8329091229	0.9042181506	0.9707789172	1.0647107370	1.0851892683	1.1902794772	1.2527629685	1.2527629685	1.3212223644	1.4109869737	1.4109869737	1.4816045409	1.4879480148	1.6292405397	1.6863989536	1.7047480922	1.7047480922	1.7671251883	1.9007633398	2.0014800002	2.0014800002	2.2499224404	2.6640398584	1.1111994042	-0.5108256238	-0.0010005003	0.8754687374	1.3350010667	2.1517622033	2.8735646396	0.6931471806	0.8329091229	1.0647107370	1.3083328197	1.3449513976	1.3449513976	2.1517622033	2.8735646396	3.1174630621	3.1179499063	1.2875783882	-0.2231435513	-0.1450257721	-0.1402526728	-0.1053605157	-0.0491902442	-0.0491902442	-0.0010005003	0.2646692981	0.8754687374	1.0647107370	1.8245492921	2.4356288668	2.9052056344	2.9069010598	3.4043663086	1.1993621918	1.2974631474	1.3083328197	1.8180767775	1.8452689087	1.9169226122	2.1400661635	2.1422989631	2.1422989631	1.8476306151	1.9848560992	-0.5333279119	0.1595645697	0.3184537311	0.3364722366	0.7884573604	2.4069451083	2.4940315576	2.5726122302	2.5750972621	3.1738784589	3.2185957857	3.2188758249	2.7346921320	1.8931119635	0.6709015716	0.6709015716	0.6709015716	0.6931471806	0.7249134959	0.7323678937	0.8484400650	0.9794533068	1.2641267271	1.8261608959	1.9198594719	1.3799918922	1.8725711120	1.9021075264	1.9031517571	1.9031517571	2.3305892894	0.6554453134	0.7719583610	1.1666830640	1.4293538506	1.4293538506	1.4350845253	1.6345206928	2.7421291990	3.1410440047	0.7092553939	0.8821132801	3.4724942635	1.0647107370	1.3083328197	1.3721954367	1.7175745710	2.1268303196	1.1462119031	1.5168839308	1.0811269743	2.2816820895	2.3247378976	0.4446858213	0.5877866649	0.5877866649	0.7716807346	0.7884573604	0.8679404709	0.9516578757	0.9858167945	0.9932517730	1.0647107370	1.0647107370	1.0986122887	1.1009429040	1.1442227999	1.1603343473	1.2527629685	1.2527629685	1.2706028866	1.2809338455	1.5475625087	1.5686159179	1.5892352051	1.7227665977	2.4246257189	0.9206810802	2.1782692889	1.5398508930	2.4217620811	2.2026542544	1.3010087668	1.7595805709	2.0014800002	2.0018853235	2.0031003084	2.0031003084	2.2727442510	2.3608540011	3.2483181155	1.5029656679	1.0370914320	-2.0465036008	-2.0387618291	-1.8776359905	-0.7020207608	-0.4210099176	-0.3227377627	-0.2666954539	-0.1421266020	-0.1334384682	-0.1333955896	-0.0870184569	0.0064095568	0.0691127674	0.0895872329	0.0898542448	0.0900061770	0.1143944472	0.1263466346	0.1459182026	0.1466650701	0.1484200051	0.1543303070	0.1696990222	0.1839499446	0.1897210318	0.2028024177	0.2030726876	0.2175963162	0.2263384422	0.2263384422	0.2900657801	0.3505047326	0.3681852682	0.3816858419	0.4231151573	0.4273343348	0.4519160660	0.4614866372	0.5052176045	0.5189411847	0.5478548078	0.5578902922	0.5916043919	0.6087490106	0.6154273604	0.6285232970	0.6340644231	0.6616716492	0.6847279357	0.7079999311	0.7184324830	0.7705681955	0.8999662574	1.0003916287	1.0656542537	1.1127257236	1.3329091892	1.3802482280	1.4498801924	1.4996230464	1.5102715844	1.5121844336	1.5229735904	1.9404562979	2.0489594936	2.1512160640	2.3491880672	2.6485552727	1.7410916108	1.7425692250	1.7425692250	1.7917594692	2.5472255610	2.5877640352	2.9332715922	2.9332715922	3.3616533896	2.8072756879	3.4341807341	3.5251833614	2.0617866064	2.8243506568	1.7426048862	3.0978374965	3.3080215891	3.3080215891	-0.8675005677	2.0298573123	2.0298573123	2.2721258855	2.6796061165	3.6844629934	3.9120136514	3.0449211487	2.4447033614	2.9345937632	0.2445550797	3.0282478652	3.0282478652	3.3593331776	-2.2218686704	-1.3604066619	0.7713570672	0.8384538268	1.1153625994	1.2512398472	1.3574711956	1.3626002495	1.3937834474	1.4553169550	1.5202017909	1.6020048275	1.6421902809	1.7282579105	1.7587354850	1.7658649715	1.7735657115	1.7987965847	1.8014577814	1.8174206335	1.8526533115	1.8607068619	1.8677520799	1.8802185214	1.8875590178	1.9199707910	1.9291168435	1.9303067382	1.9703782720	1.9789512508	1.9829478630	1.9863389960	1.9945374855	2.0114171423	2.0121159866	2.0198588190	2.0342349606	2.0509577935	2.0559669223	2.0581427379	2.0668627595	2.0712743621	2.0733614924	2.0980803060	2.1026204339	2.1035367348	2.1038133160	2.1039320495	2.1058187010	2.1248579289	2.1272420500	2.1298054656	2.1345146730	2.1428882508	2.1457869195	2.1460592558	2.1511780252	2.1543617547	2.1600789974	2.1619154902	2.1658007211	2.1709614001	2.1768962926	2.1786565654	2.1921337225	2.1954559108	2.1967598866	2.2076081708	2.2095214867	2.2149425699	2.2212870679	2.2309723018	2.2432354991	2.2464519816	2.2468058343	2.2475249033	2.2487123495	2.2571351968	2.2686348610	2.2719747240	2.2757138150	2.2814841496	2.2910184509	2.2992701901	2.3351774589	2.3387439562	2.3496558070	2.3823366133	2.3971314806	2.4103847831	2.4478634228	2.4502641923	2.4503418601	2.4590131522	2.4754537130	2.4834135205	2.4844314577	2.4907806875	2.4984663752	2.5128622915	2.5272474903	2.5272474903	2.5296218528	2.5775836100	2.6191743732	2.6327987187	2.6332348637	2.6552980192	2.6690215783	2.6932124159	2.6961085922	2.7136638620	2.7155510784	2.7786276833	2.7808297985	2.8278056525	2.878483783	2.884707205	2.90561085	2.908997551	2.917936038	2.925136652	2.926603096	2.961421957	2.98045045	3.011490396	3.033848178	3.056595321	3.061981064	3.097156417	3.12801224	3.297027023	3.713944585	4.842900125	1.635521791	1.908059925	2.231733352	2.231733352	3.208421367	3.469796731];

%assignment of columns and rows
[inputs,Rows] = size(p);

%normalization between -1 and 1
[pn,ps] = mapminmax(p);
[tn,ts] = mapminmax(t);

%index creation for training, validation and testing
p1 = 1:5:Rows;
p2 = 2:10:Rows;
p3 = 3:5:Rows;
p4 = 4:10:Rows;
p5 = 5:5:Rows;
p7 = 7:10:Rows;
p9 = 9:10:Rows;

%percentage assignment for: training(80%), validation(10%) and testing(10%)
aa = [p1 p3 p5 p7 p9];
vv = [p2];
tt = [p4];

%Creation of training, validation and testing vectors
val.P = pn(:,vv); val.T = tn(:,vv);
test.P = pn(:,tt); test.T = tn(:,tt);
trainP = pn(:,aa); trainT = tn(:,aa);

%initial parameters
hiddenNeurons = 1;
maxHiddenNeurons = 35;
iterations = 1000;
targetIdeal = 0.99;
flagHiddenNeurons = 1;
learningRate = 0.01;
lrOption= 1 ;

%cycle that controls the number of hidden neurons
while(hiddenNeurons <= maxHiddenNeurons & flagHiddenNeurons == 1)

    %cycle that controls the inicialized learning rate (0.01, 0.001, 0.0001, 0.00001)
    while (lrOption <= 4)
        flagLearningRate = 1;
        rInitial = 0.1;        
        n = 1;       
        rCalculated = [];        
        
        %cycle that creates the ANN
        while (flagLearningRate == 1)
            net = newff(minmax(pn(:,aa)),[hiddenNeurons 1],{'tansig' 'purelin'},'trainlm');            
            net.trainParam.mu = learningRate;
            net.trainParam.epochs = 3000;
            net.trainParam.goal = 1e-6;
            
            [net,tr] = train(net,trainP,trainT,[],[],val,test);
            a = sim(net,pn);
            [m,b,r] = postreg(a,tn);          
            rCalculated(n) = r;                       
            
            if (r > rInitial)
                rInitial = r;
                slope = m;
                intercept = b;
                
                %denormalize output of the ANN
                for i=1:length(t)                    
                    outputANN(i) = ( ((a(i)+1)/2)*(max(t)-min(t)) )+min(t);
                end                

                %calculate the correlation coefficient r for Global set
                aMean = mean(outputANN);
                tMean = mean(t);                               
                for i=1:length(t)
                    t_tMean(i) = (t(i)-tMean).^2;               
                    a_aMean(i) = (outputANN(i)-aMean).^2;                    
                    t_tMean_a_aMean(i) = (t(i)-tMean)*(outputANN(i)-aMean);
                end                
                rGlobal = (sum(t_tMean_a_aMean))/sqrt((sum(t_tMean))*(sum(a_aMean)));
                
                %calculate the correlation coefficient r for training set
                aMeanTrain = mean(outputANN(:,(aa)));
                tMeanTrain = mean(t(:,(aa)));                
                for i=1:length(t)
                    t_tMeanTrain(i) = (t(i)-tMeanTrain).^2;               
                    a_aMeanTrain(i) = (outputANN(i)-aMeanTrain).^2;                    
                    t_tMeanTrain_a_aMeanTrain(i) = (t(i)-tMeanTrain)*(outputANN(i)-aMeanTrain);
                end
                rTrain = (sum(t_tMeanTrain_a_aMeanTrain(:,aa)))/sqrt((sum(t_tMeanTrain(:,aa)))*(sum(a_aMeanTrain(:,aa))));
                                
                %calculate the correlation coefficient r for validation set                
                aMeanVal = mean(outputANN(:,(vv)));
                tMeanVal = mean(t(:,(vv)));                
                for i=1:length(t)
                    t_tMeanVal(i) = (t(i)-tMeanVal).^2;               
                    a_aMeanVal(i) = (outputANN(i)-aMeanVal).^2;                    
                    t_tMeanVal_a_aMeanVal(i) = (t(i)-tMeanVal)*(outputANN(i)-aMeanVal);
                end
                rVal = (sum(t_tMeanVal_a_aMeanVal(:,vv)))/sqrt((sum(t_tMeanVal(:,vv)))*(sum(a_aMeanVal(:,vv))));
                
                %calculate the correlation coefficient r for testing set
                aMeanTest = mean(outputANN(:,(tt)));
                tMeanTest = mean(t(:,(tt)));                
                for i=1:length(t)
                    t_tMeanTest(i) = (t(i)-tMeanTest).^2;               
                    a_aMeanTest(i) = (outputANN(i)-aMeanTest).^2;                    
                    t_tMeanTest_a_aMeanTest(i) = (t(i)-tMeanTest)*(outputANN(i)-aMeanTest);
                end
                rTest = (sum(t_tMeanTest_a_aMeanTest(:,tt)))/sqrt((sum(t_tMeanTest(:,tt)))*(sum(a_aMeanTest(:,tt))));
            
                %calculate the RMSE global
                for i=1:length(t)
                    tmpDifference(i)=(t(i)-outputANN(i));
                end
                tmp1=tmpDifference.^2;
                tmp2=sum(tmp1);
                rmse=sqrt(tmp2/length(t));
                
                %calculate the MAE global
                for i=1:length(t)
                    errorAbs(i)=abs(t(i)-outputANN(i));                    
                end
                mae=(sum(errorAbs))/(length(t));
                                    
                %Relative contribution - Garson algorithm 1991                
                contribution=[];
                c=[];
                R=[];
                S=[];                
               
                for mm=1:hiddenNeurons        
                    for k=1:inputs
                        c(mm,k)=net.IW{1,1}(mm,k)*net.LW{2,1}(1,mm);
                    end
                end                
               
                for mm=1:hiddenNeurons
                    for k=1:inputs
                        R(mm,k)=abs(c(mm,k))/(abs(c(mm,1))+abs(c(mm,2))+abs(c(mm,3))+abs(c(mm,4)));
                    end
                end
                
                %different cases for the number of hidden neurons                
                switch hiddenNeurons
                    case 1                        
                        for k=1:inputs
                            S(k)=R(1,k);
                        end
                    case 2                        
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k);
                        end
                    case 3                        
                        for k=1:inputs 
                            S(k)=R(1,k)+R(2,k)+R(3,k);
                        end
                    case 4                        
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k);
                        end                      
                    case 5                        
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k);
                        end
                    case 6
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k);
                        end
                    case 7
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k);
                        end
                    case 8
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k);
                        end
                    case 9
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k);
                        end
                    case 10
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k);
                        end
                    case 11
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k);
                        end
                    case 12
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k);
                        end
                    case 13
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k);
                        end
                    case 14
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k);
                        end
                    case 15
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k);
                        end                        
                    case 16
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k);
                        end
                    case 17
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k);
                        end
                    case 18
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k);
                        end
                    case 19
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k);
                        end
                    case 20
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k);
                        end
                    case 21
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k);
                        end
                    case 22
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k);
                        end
                    case 23
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k);
                        end
                    case 24
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k);
                        end
                    case 25
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k);
                        end
                    case 26
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k)+R(26,k);
                        end
                    case 27
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k)+R(26,k)+R(27,k);
                        end
                    case 28
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k)+R(26,k)+R(27,k)+R(28,k);
                        end
                    case 29
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k)+R(26,k)+R(27,k)+R(28,k)+R(29,k);
                        end
                    case 30
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k)+R(26,k)+R(27,k)+R(28,k)+R(29,k)+R(30,k);
                        end
                    case 31
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k)+R(26,k)+R(27,k)+R(28,k)+R(29,k)+R(30,k)+R(31,k);
                        end
                    case 32
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k)+R(26,k)+R(27,k)+R(28,k)+R(29,k)+R(30,k)+R(31,k)+R(32,k);
                        end
                    case 33
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k)+R(26,k)+R(27,k)+R(28,k)+R(29,k)+R(30,k)+R(31,k)+R(32,k)+R(33,k);
                        end
                    case 34
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k)+R(26,k)+R(27,k)+R(28,k)+R(29,k)+R(30,k)+R(31,k)+R(32,k)+R(33,k)+R(34,k);
                        end                                                                                
                    case 35
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k)+R(21,k)+R(22,k)+R(23,k)+R(24,k)+R(25,k)+R(26,k)+R(27,k)+R(28,k)+R(29,k)+R(30,k)+R(31,k)+R(32,k)+R(33,k)+R(34,k)+R(35,k);
                        end    
                    otherwise
                        disp('option not found')
                end
                
                % contribution of each input    
                for k=1:inputs
                    contribution(k)=S(k)/(S(1)+S(2)+S(3)+S(4));
                end
                
                %saving weights of the ANN in txt files
                bestIteration=n;
                IW=net.IW{1,1};
                lw=net.LW{2,1};
                LW=lw';
                b1=net.b{1};
                b2=net.b{2};                
                filename1 = [num2str(hiddenNeurons),'_neurons_lr_',num2str(learningRate),'_IW','.txt'];
                filename2 = [num2str(hiddenNeurons),'_neurons_lr_',num2str(learningRate),'_b1','.txt'];
                filename3 = [num2str(hiddenNeurons),'_neurons_lr_',num2str(learningRate),'_LW','.txt'];
                filename4 = [num2str(hiddenNeurons),'_neurons_lr_',num2str(learningRate),'_b2','.txt'];              
                save(filename1,'IW','-ascii');
                save(filename2,'b1','-ascii');
                save(filename3,'LW','-ascii');
                save(filename4,'b2','-ascii');                
     
            end %end of if (r > rInitial)
            
            %if the ideal target is reached or all the iterations are executed
            if (r >= targetIdeal || n == iterations)
              flagLearningRate = 0;
            else              
              n = n+1
            end
        
        end % end of while (flagLearningRate == 1)
        
        %for report in txt        
        rMin = min(rCalculated);
        rSort = sort(rCalculated);
        rMedian = median(rSort);        
        input1 = contribution(1);
        input2 = contribution(2);
        input3 = contribution(3);
        input4 = contribution(4);
       
        %creation of results vector
        results = [inputs, hiddenNeurons, iterations, learningRate, rMin, rMedian, rGlobal, rTrain, rVal, rTest, rmse, mae, slope, intercept, input1, input2, input3, input4, bestIteration];
        
        %save in file txt        
        dlmwrite('report_ANN12.txt',results,'-append','delimiter',',','newline','unix');
        results = [];
                
        %different cases for learning rate
        switch(lrOption)
            case 1
                learningRate = 0.001;
                lrOption = lrOption+1;                
            case 2
                learningRate = 0.0001;
                lrOption = lrOption+1;
            case 3
                learningRate = 0.00001;
                lrOption = lrOption+1;
            case 4
                lrOption = lrOption+1;
            otherwise
                disp('option not found')
        end %end switch(lrOption)           
        
    end %end of while (lrOption <= 4)
    
    %we reset parameters for the next hidden neuron
    hiddenNeurons = hiddenNeurons+1;
    lrOption = 1;
    learningRate = 0.01;

end %end of while(hiddenNeurons <= maxHiddenNeurons & flagHiddenNeurons == 1)