% Name of code: ScriptANN30
% Developer and contact address: A. Acevedo-Anicasio and Instituto de 
% Energias Renovables, Universidad Nacional Autonoma de Mexico; Priv. 
% Xochicalco s/n, Temixco, 62580
% Morelos, Mexico
% Telephone number: Tel.: +52 (55) 5622-9774, Fax: +52 (55)5622-9791
% e-mail: esg@ier.unam.mx

% Year first available: 2018
% Suggested hardware: Intel Core Processor i5-2300, 2.80GHz, Ram Memory 
% 4 GB, and  a Hard drive 500 GB
% Software requirements: Matlab for Windows v. R2017b (MathWorks, 2017)
% Programming language: MATLAB
% Programming file size: 37 kB with 282 lines of code

%The MIT License (MIT)
%Copyright (c) 2018 D. Pérez-Zárate, E. Santoyo, A. Acevedo-Anicasio, C. García-López, L. Díaz-González

clear all
close all
clc

%target: BHT (°C) 
t = [239	250	289	296	305	295	275	270	320	325	327	330	330	324	340	290	300	300	300	170	170	225	320	300	300	325	295	300	215	247	182	225	240	240	278	250	250	260	260	240	260	260	270	250	250	240	240	240	250	250	230	260	240	250	240	240	250	240	240	250	250	260	250	240	270	212	238	205	217	215	338	343	325	325	281	281	281	293	293	293	304	304	304	279	279	300	300	300	292	292	292	296	296	296	280	280	280	306	306	306	287	287	287	314	314	315	315	267	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	271	287	287	287	287	287	287	287	287	287	287	287	287	287	287	287	287	287	271	271	271	271	271	271	271	271	277	277	277	277	277	277	277	302	302	302	302	302	302	302	302	302	248	248	278	278	278	278	302	302	302	302	302	302	302	302	302	265	265	265	265	265	265	265	265	265	265	265	276	276	276	276	276	276	267	267	267	267	267	267	267	334	334	262	262	274	274	274	274	274	352	352	311	311	311	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	296	301	301	281	327	327	329	329	329	329	329	329	329	329	329	329	329	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	204	356	356	356	356	268	319	319	319	319	319	267	267	267	267	262	262	262	330	330	363	304	300	350	290	322	322	322	322	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	340	284	284	284	284	307	307];
    
%inputs: ln(CO2), ln(H2S), ln(CH4), ln(H2) mmol/mol
p = [5.986452005	8.072779333	7.63336965	6.956545443	6.672032945	7.098375639	6.740064333	6.719064444	6.781302223	6.657481152	6.713830974	6.720783667	6.768216327	6.722621054	6.690414129	6.629263405	6.824351772	6.833472254	6.843904589	6.568053912	6.6334066	6.633235725	6.618640899	6.596734059	6.632795739	6.694230069	6.667268504	6.740192249	6.7464587	6.561502457	6.757289418	6.576905069	6.844049779	6.816153286	6.686277007	6.847155657	6.845347819	6.864743388	6.841188035	6.863385331	6.845028449	6.843323419	6.833570381	6.838190816	6.874301903	6.880281302	6.880692359	6.877914437	6.887858647	6.888470518	6.879561545	6.858670071	6.88007571	6.843323419	6.865265227	6.846730577	6.844602464	6.860978087	6.856146145	6.858985115	6.872646102	6.840974245	6.849914279	6.832816192	6.851290742	6.746412129	6.722629795	6.629363253	6.741700695	6.576469569	6.761100153	6.807012149	6.706862337	6.718409107	6.56948142	6.743705767	6.778784898	6.706250903	6.7469995	6.777646594	6.711618733	6.749345542	6.777646594	6.769641977	6.779126136	6.718167386	6.745706827	6.770789424	6.6956753	6.738389433	6.756932389	6.715625781	6.739218277	6.774223886	6.69542802	6.714534541	6.717804695	6.66949809	6.713320654	6.814542897	6.703188113	6.760762255	6.774223886	6.731733835	6.73459166	6.738270971	6.744059186	6.891625897	6.796028989	6.85259944	6.857385768	6.859239177	6.86051691	6.865891075	6.865891075	6.866349781	6.867974409	6.868944802	6.871091295	6.872128101	6.872128101	6.872128101	6.874198495	6.873784759	6.875025454	6.876264612	6.878326468	6.878326468	6.878944197	6.882437471	6.882437471	6.893656355	6.893656355	6.836384941	6.698268054	6.776506992	6.776506992	6.786716951	6.821107472	6.88857246	6.665683718	6.698268054	6.705639095	6.705883863	6.776506992	6.785587645	6.801283034	6.863803391	6.888164629	6.888164629	6.89304765	6.893265812	6.893656355	6.893656355	6.894820349	6.897704943	6.897735246	6.898007928	6.659443441	6.763884909	6.763422908	6.781708946	6.830874235	6.867974409	6.887552572	6.830765225	6.869741837	6.870053412	6.87036489	6.87036489	6.870053412	6.872566347	6.886531643	6.886122979	6.831037063	6.847063217	6.88948947	6.889591308	6.894852394	6.896198331	6.741676331	6.771821002	6.771935556	6.778146469	6.833031733	6.842683282	6.84694314	6.893656355	6.734104026	6.840353997	6.842976729	6.848885991	6.868005626	6.86774145	6.881000542	6.884183638	6.894264689	6.894264689	6.894264689	6.894670039	6.856970276	6.864553915	6.865473887	6.882642578	6.882642578	6.882437471	6.874210017	6.880281302	6.884480511	6.88857246	6.888164629	6.888164629	6.891829128	6.652505614	6.677780951	6.871220954	6.877944171	6.814256767	6.845239245	6.876264612	6.882129731	6.884486652	6.862967096	6.868960793	6.634503548	6.770846762	6.879664399	6.804649996	6.873061344	6.874451824	6.876264612	6.877296071	6.877296071	6.878326468	6.879379467	6.880384082	6.879972898	6.88029672	6.880384082	6.880227299	6.881411304	6.882437471	6.882437471	6.883462586	6.883736115	6.884315706	6.884486652	6.885714148	6.891625897	6.895682698	6.895682698	6.811927844	6.853617944	6.862092894	6.768272401	6.834607	6.652313201	6.755857393	6.782281621	6.81710821	6.82437367	6.82448236	6.82448236	6.839904612	6.850390962	6.851866177	6.870711554	6.646663741	6.825077724	6.833167688	6.846725417	6.851696389	6.855704833	6.856516134	6.861069498	6.867151931	6.869741837	6.869741837	6.869014451	6.871765882	6.875520596	6.876177597	6.876472121	6.876495413	6.878271388	6.878755977	6.879980371	6.880116542	6.880239043	6.881331298	6.881216447	6.881599671	6.882142766	6.882930104	6.884591747	6.884845944	6.885300584	6.886632812	6.88665419	6.887183385	6.887593512	6.887735633	6.888056731	6.88820042	6.888021359	6.888453767	6.889366776	6.889693136	6.889639936	6.889955909	6.890655639	6.891089235	6.891544823	6.891539451	6.891590865	6.892345714	6.892405782	6.892789751	6.89312669	6.893451036	6.893957886	6.894867985	6.89511094	6.895896111	6.896144835	6.896243239	6.896376176	6.896526926	6.897689237	6.897650193	6.899263917	6.899752396	6.899399573	6.901682101	6.901917323	6.791639436	6.809039306	6.817611729	6.817611729	6.657273937	6.609349243	6.715989263	6.728923025	6.738270971	6.760067006	6.769641977	6.803616239	6.803616239	6.830220563	6.844815479	6.870780043	6.870780043	6.762052133	6.80682936	6.549336102	6.662374877	6.723881642	6.779123275	6.656713392	6.777646594	6.780149154	6.780149154	6.781071852	6.658350824	6.662515057	6.667743928	6.705507381	6.708956326	6.722793852	6.741959627	6.745018636	6.734201181	6.749838407	6.75269344	6.760350885	6.762290325	6.771909804	6.772407617	6.77286974	6.776498832	6.780524464	6.78422354	6.785665196	6.786407187	6.787556103	6.788464041	6.789656681	6.791549567	6.791634195	6.793369443	6.793593858	6.793867583	6.794208347	6.795701124	6.796578812	6.796546922	6.796889769	6.797583399	6.796387479	6.797841494	6.798271881	6.799351726	6.800137571	6.800860506	6.802169933	6.802241785	6.800361059	6.802885414	6.803050658	6.800406135	6.80364949	6.803946259	6.805425729	6.805708401	6.805720408	6.8069691	6.808401602	6.807594657	6.810850126	6.8109955	6.811086945	6.809873029	6.812973302	6.812990992	6.812971368	6.813350982	6.813402962	6.813476137	6.814410545	6.81438922	6.81479193	6.814929584	6.816014897	6.816999957	6.818109924	6.818885195	6.816190722	6.819325811	6.819471812	6.820011262	6.820244419	6.820670835	6.821107472	6.821050303	6.820917929	6.822865753	6.82293983	6.823259874	6.823632953	6.824395355	6.824453631	6.82501801	6.825196103	6.828820291	6.825506375	6.825210062	6.82656831	6.826683549	6.826577543	6.827435887	6.827566507	6.827196047	6.828820291	6.828457742	6.827979844	6.829436441	6.829725664	6.783248997	6.830823827	6.83059056	6.831473208	6.830977125	6.832830778	6.832926186	6.834209381	6.83517113	6.835396638	6.83727787	6.837616107	6.838202695	6.83853474	6.838527592	6.837056467	6.839582099	6.839974683	6.840915182	6.841387753	6.841697693	6.842370596	6.845377343	6.849189412	6.851088745	6.854349235	6.859211227	6.861872897	6.865253203	6.876964645	6.850126166	6.851819647	6.851819647	6.853822559	6.63046282	6.774223886
3.5085559	3.923951576	4.271095074	4.86753445	5.283203729	2.302585093	4.171399801	4.629260116	4.338795939	4.558236983	4.587702318	4.427617796	4.201773317	4.442698732	4.793294144	4.687691658	3.72119925	3.746929246	3.611826892	4.753566191	4.898503156	4.557178281	4.652528043	4.231628609	2.456407268	3.80517077	1.286548579	4.191496242	4.677210023	3.930413297	4.774965558	4.129388579	2.660361172	3.466088258	4.97135532	2.949688335	3.005682604	2.624668592	2.694627181	2.617395833	2.980618636	2.985681938	3.250374492	3.152736022	2.302585093	2.163323026	2.151762203	2.379546134	1.62924054	1.526056303	2.332143895	3.005682604	2.219203484	2.990719732	2.302585093	3.010620886	3.039749159	2.557227311	2.879198457	2.740840024	2.282382386	3.126760536	2.827313622	3.117949906	2.912350665	4.007333185	4.700480366	4.248495242	4.49980967	4.077537444	4.502966823	2.008220851	3.974058396	4.080921542	4.041295341	4.058717385	3.864931398	3.910021003	3.591817741	3.642835516	4.370712875	3.987130478	3.862832761	3.956996371	3.456316681	4.258445573	4.041295341	3.895893623	4.422448549	4.203198967	3.987130478	4.060443011	4.019980147	3.875359021	4.053522568	4.062165664	4.087655574	3.925925911	3.96271612	3.269568939	4.117409835	3.808882247	3.879499814	4.019980147	4.048300624	3.994524227	3.923951576	2.272125886	3.379292546	3.320529508	3.388213454	3.457325635	3.446011397	3.269568939	3.269568939	3.349904087	3.401197382	3.306996586	3.165475048	3.222867846	3.288401888	3.288401888	3.165475048	3.164208424	3.001962823	3.091042453	3.126760536	3.126760536	3.044522438	2.944438979	2.833213344	2.2300144	2.2300144	2.310553263	1.960094784	2.292534757	2.240709689	2.240709689	1.131402111	2.282382386	2.332143895	1.960094784	2.054123734	2.055404964	2.302585093	1.931521412	2.041220329	1.526056303	2.280339484	2.280339484	1.769854634	1.921617456	1.902107526	1.667706821	1.763954777	1.774952351	1.773255998	1.773255998	4.665447855	4.562262685	4.561740628	4.213030893	4.15575319	3.27336401	2.714694744	3.33070729	3.230804396	2.970414466	3.198673118	3.198673118	3.198673118	2.874581072	2.727852828	2.724579503	3.489767443	3.326366071	2.155244505	2.151762203	1.702199393	1.29479922	4.176270443	4.42424765	4.423648309	4.198088772	3.879499814	3.299533728	3.642835516	2.2300144	4.56635659	2.197224577	2.32630162	2.970414466	2.186051277	2.182340445	2.315501318	2.195111235	2.033397603	2.033397603	2.033397603	2.028148247	2.93561065	3.122919277	3.134189017	2.527327366	2.527327366	2.525728644	2.393495398	2.835563521	2.472581	2.424802726	2.424802726	2.424802726	2.269028309	4.428864819	4.617721093	3.185194938	3.015579312	2.795742499	2.879872387	3.214867803	1.941615225	2.379546134	3.370394473	3.180338518	4.679833371	4.417622999	2.797281335	2.550460281	2.935769932	2.966766795	2.809402695	2.970414466	2.970414466	2.995732274	2.772588722	2.821378886	2.821378886	2.869318349	2.844909384	2.861874073	2.772588722	2.867898902	2.844909384	2.821378886	2.738061975	2.678071978	2.772588722	2.681021529	2.2300144	1.960094784	1.960094784	3.922272462	3.552859253	3.262487625	4.458985881	3.149697222	4.056209926	4.134446297	4.309509704	4.172847624	4.131961426	4.131961426	4.131961426	3.815952537	3.760502198	3.451573589	3.025339618	4.967343264	4.281831075	3.702823825	3.518957017	3.604693227	3.590274195	3.413818403	2.997702604	3.419503695	3.384390263	3.384390263	2.397895273	2.372623822	2.259876266	3.136837243	2.461100604	2.459957923	2.917814788	2.615812872	3.046316244	1.303094304	2.622657541	2.94917988	2.658757537	2.872661627	2.172327268	2.475167266	2.73291629	2.393171372	2.624039352	2.542326639	2.055043907	2.255897048	2.518970682	2.396779826	2.466342879	2.824985405	2.748180142	2.808200827	1.911117346	2.388762789	2.386698733	2.459473165	2.346322816	2.448336861	1.922132701	2.107456685	0.420630544	1.201504936	1.80905971	2.108404153	1.880775697	1.4461854	1.975839059	0.448704719	2.010168013	1.63064536	1.861272317	1.713871933	0.559751591	-0.311710924	1.058950013	0.2422843	-0.30353859	0.921563223	0.125547656	-2.271469583	1.043753971	3.824670023	3.931825633	4.03158224	4.03158224	4.893256603	5.170483995	4.575329344	4.644748626	4.656338473	4.522874943	4.189654742	4.150724896	4.150724896	3.661550641	3.63758616	3.253856794	3.253856794	4.311690319	4.110873864	4.947216956	4.2877899	4.472665655	4.477624847	4.958301627	4.276666119	4.416911037	4.416911037	4.350606386	4.345672596	5.260923477	4.294387642	5.114398046	4.467006071	4.964226136	4.891751871	4.851851273	4.587964779	4.781353279	4.849021028	4.488337262	4.767980006	4.697839258	4.58043592	4.600490407	4.524356211	3.900590681	4.478182852	4.535559052	4.341749016	4.441724181	4.486422811	4.278986173	4.441257147	4.550177408	4.33317645	4.43722466	4.28619639	3.976298171	4.419093246	4.356004098	4.461885928	4.337559961	4.507747094	4.077093904	4.140446832	4.219496626	4.344810973	4.1756237	4.292690353	4.264057093	4.321757486	3.784317101	4.29663649	4.314167356	4.352616196	4.306033459	4.315835811	4.252909313	4.350425097	4.302877509	4.233263328	4.302074552	4.153541177	4.182672205	4.154344925	4.161438828	4.233830186	4.252324056	4.064392539	4.24222084	4.250601509	4.357061703	4.253837327	4.064642563	4.244262163	4.27517436	4.331035696	4.213637621	4.179463925	4.047556895	4.121166473	4.178726698	3.992612123	3.98731121	4.074021227	3.911467599	4.114688603	4.110873864	3.997942308	3.956487007	4.149549686	4.140514897	4.138432691	4.104052996	4.187384138	3.896271175	4.138596859	4.024943607	4.063197833	4.030078837	3.900052242	4.024126624	4.030335644	4.002728252	4.032194594	4.010218206	4.071141137	4.063197833	3.971954301	4.109128862	3.887546407	4.213153097	4.168334352	4.156084468	3.975139148	3.81885147	4.021656968	3.999238455	3.927318556	3.900198338	3.969186178	3.964705832	3.930976302	3.947497769	3.94108131	3.950091353	3.855581328	3.905731646	4.056768606	3.877568348	3.922805844	3.560493686	3.875208874	3.92145546	3.812934008	3.627451117	3.913950836	3.383026403	3.466976111	3.514102215	2.820491391	3.110462993	3.583518938	3.718438256	3.718438256	3.400517804	4.797289352	4.49980967
-0.510825624	1.589235205	-0.0010005	0.955511445	0.993251773	1.098612289	1.767032014	-0.040448591	-0.006549129	-1.102486002	-1.22882078	-0.781087412	-1.023076897	-0.342137974	-1.954612434	1.189933314	-0.760476863	-1.093807012	-1.091953806	2.837649969	1.154127297	2.617733672	0.358570427	2.635807247	0.769852052	-0.018927841	-0.124331258	0.578463991	1.734709199	1.991699415	0.655476814	0.433864583	-0.718857303	-0.370844296	-0.045462374	2.653241965	2.58021683	1.931521412	2.960105096	2.174751721	2.721295428	2.721295428	2.624668592	2.525728644	1.458615023	1.280933845	1.193922468	1.16315081	0.955511445	1.098612289	0.641853886	1.435084525	1.098612289	2.617395833	2.48490665	2.32238772	2.163323026	2.272125886	2.116255515	2.272125886	1.85629799	2.406945108	2.459588842	2.821378886	2.197224577	2.079441542	2.48490665	2.197224577	2.041220329	1.62924054	0.674325426	1.961700835	3.790984677	3.608211551	3.751854253	3.634951112	3.440418095	3.883623531	3.688879454	3.292126287	3.683866912	3.698829785	3.414442608	3.226843995	3.384390263	3.523415014	3.716008122	3.499533282	3.751854253	3.691376334	3.443618098	3.718438256	3.605497845	3.335769576	3.927896355	3.931825633	3.858622229	3.817712326	4.039536326	3.0301337	3.790984677	3.758871826	3.61361697	3.763522997	3.706228092	3.616308761	3.532225644	-1.46967597	0.43567095	0.460364383	0.448524598	0.172271221	0.376379527	0.131028262	0.09531018	0.253866724	-1.021651248	-0.314710745	-0.798507696	-0.328504067	-1.139434283	-1.139434283	-0.562118918	-0.570929548	-0.108699417	0.09531018	-0.733969175	-0.733969175	-0.579818495	-0.544727175	-0.46203546	-1.237874356	-1.237874356	-1.676646662	-0.301105093	-2.525728644	-1.660731207	-1.660731207	-2.302585093	-1.966112856	-0.891598119	-0.301105093	-1.714798428	-1.737271284	-2.525728644	-0.867500568	-1.237874356	-1.46967597	-1.995100393	-1.995100393	-1.127011763	0.1806535	-0.867500568	-0.755022584	0.047353228	-2.407945609	-2.375155786	-2.375155786	0.939920809	-1.427116356	-1.443923474	-0.805196684	-0.051293294	-0.223143551	-3.218875825	-0.411209878	-0.215671536	-0.820980552	-1.937941979	-1.937941979	-1.966112856	-0.277071893	-3.506557897	-3.473768074	0.648942126	-2.525728644	-0.012072581	-0.010050336	0.528861986	0.55501637	-0.718781141	-0.926341068	-0.916290732	-1.339410775	1.098612289	0.182321557	-2.407945609	-2.407945609	-0.432322562	-0.832409248	-0.036663984	-2.780620894	-0.463624022	-0.466854513	0.214304603	-0.022245609	-0.494296322	-0.494296322	-0.494296322	-0.494296322	-0.182721637	-0.286899978	-0.204567166	-0.546452801	-0.546452801	-0.544727175	-0.934686654	-0.644357016	0.286681572	-2.302585093	-2.3330443	-2.3330443	-1.465337568	0.305857347	-0.541284831	-0.024292693	-0.044565451	-2.504804098	-6.907755279	-0.0010005	-2.375155786	-1.897119985	-0.430782916	-0.37028833	0.795311544	-0.594207233	-0.903868212	0.21993842	0.735248357	-0.240798487	0.148420005	-0.105360516	-0.105360516	-0.400477567	-0.303811454	-0.274436846	-0.275753502	-0.612489278	-0.46203546	-0.148744934	-0.072570693	-0.713349888	-0.713349888	0.09531018	-0.412489723	-0.035627178	-0.342490309	-0.322963887	-0.527632742	-1.049822124	-1.049822124	1.176056114	-0.780886095	-0.388750774	0.808990781	-0.68121861	-0.623621118	0.292669614	-0.592397277	0.477475644	-0.967584026	-0.954511945	-0.954511945	-0.103140759	-0.705219762	0.19062036	0.21913553	1.96712487	-2.549660688	-0.624808737	1.352708368	0.331456795	0.023922837	-0.279253929	-3.970380664	-0.737874246	-0.52256088	-0.52256088	-0.579818495	-0.57205328	-0.944831378	-2.351058201	-1.412610411	-1.356085948	-0.73071337	-0.575695552	0.152445388	-0.91824688	-0.704794131	-0.221241859	-2.299755547	0.055739799	-0.624159922	-0.697191605	-4.80569349	-3.13298439	-2.907255408	-0.111177986	-3.507692379	0.181817449	-2.723241048	0.161804249	-2.907845611	-0.826436487	-1.165286609	-2.044948075	0.011305569	0.444685821	0.441821108	0.452580506	-0.654966743	0.139447175	-0.585204085	-0.65580071	-0.049373085	0.719928812	-0.54648211	-1.858826046	-0.925714577	0.49520911	-0.765112578	-0.524232263	-3.068460037	-0.210078339	-0.766350635	-0.656979551	0.528002893	0.509883475	-3.011137572	0.495280814	-0.648379076	-0.265460023	0.16318276	-2.115534781	-1.070373129	3.030545698	3.097385927	1.785238252	1.785238252	1.510639729	3.454422143	3.485814227	3.023281057	3.035145276	2.997730276	3.410817625	1.502743174	1.502743174	1.890063723	-0.385662481	-2.659260037	-2.659260037	3.164194841	2.397895273	-0.235520961	3.902769887	3.541613023	-0.053268085	3.020083418	1.427916036	0.903002838	0.903002838	2.664728084	-2.204949269	1.785580714	0.769747441	0.503288719	-4.358363622	0.693803357	0.617121921	0.967985699	1.003102028	-0.187194586	-0.294900511	-7.654329119	0.387632934	1.051098696	0.493582887	-1.687024462	-1.687896174	-0.047362438	0.859995684	0.577727479	0.312382166	-0.642234463	0.685950007	1.969504501	1.300499101	-2.789260637	1.568335414	-2.464778815	0.592854941	-2.896685865	0.421626131	-0.586038405	1.118082746	-0.332148746	0.170693957	-0.368360758	-0.64704491	0.057859984	0.510411761	-0.346449008	-0.545203021	1.911690491	0.752044155	0.134090943	-0.496805121	1.082967153	-0.450533074	-1.834526998	0.402599349	1.232406577	-2.707614573	0.051806858	0.247418259	0.63205482	0.239559307	1.33712208	-0.738507333	-1.099970443	0.325382118	-0.42396559	-1.498226452	-0.283532225	-0.405819121	1.208456877	-0.027005133	-1.001539541	-2.8336194	-0.825791925	0.390000847	-0.661932016	0.029113023	2.127396944	0.548449059	1.084953686	-1.146640549	0.083644398	1.228769904	0.755719526	1.285105725	1.280933845	-0.942893988	-0.248190731	0.274024561	0.215694393	0.472802222	-1.671443129	-0.726807436	-0.900976743	0.186322735	0.120230164	-0.936493439	0.357234715	0.882879637	-1.688989817	0.467026183	-0.679334872	0.790028105	0.630991041	-0.208341247	-0.936493439	0.911758573	-0.490191349	-0.491919406	-9.733479537	-2.798302258	-0.181317887	0.633904802	0.116063585	-0.051959726	-1.930906785	1.144227111	0.709408898	-3.085914672	-0.504452173	-0.39477212	-0.264048147	0.145061054	0.076651285	0.064692931	-1.492201877	0.051219542	0.611373203	0.700802487	-1.827771917	-0.203903496	0.229940543	-0.061834569	0.505529621	-5.910748124	-1.453502316	-1.245374226	0.680972742	0.462643323	-3.133132643	1.134622726	-0.783071888	-0.783071888	-1.051739962	3.354453079	3.253083996
1.131402111	2.660259537	1.931521412	2.890371758	2.815408719	2.890371758	1.673505956	4.115826928	3.619673272	4.720355832	4.304910231	4.399089712	4.144351086	4.42236425	4.222954393	4.805474693	3.586194018	3.252430515	3.198090439	4.152589471	4.589516043	0.946260368	4.848860337	3.888683858	2.99648825	4.053294804	3.705010129	4.026728884	1.281289698	4.589658926	2.928461437	2.570001468	0.463136595	-0.694631373	2.741556613	2.975529566	3.025291076	2.727852828	2.867898902	2.653241965	2.87356464	2.844909384	3.214867803	3.17805383	2.778819272	2.595254707	2.57261223	2.63905733	2.370243741	2.282382386	2.701361213	3.095577609	2.624668592	2.990719732	2.32238772	3.139832618	3.325036021	2.827313622	2.975529566	2.839078464	2.667228207	3.242592351	3.034952987	3.222867846	3.104586678	-0.916290732	-0.105360516	0.693147181	-0.510825624	-0.0010005	3.200054071	0.52661631	4.149463861	3.955082495	2.87356464	3.039749159	3.005682604	3.811097087	4.180522258	3.850147602	3.353406718	3.465735903	3.218875825	3.608211551	3.681351188	3.113515309	3.449987546	3.280911216	3.711130063	3.280911216	3.549617387	3.723280881	3.650658241	3.346389145	4.000033883	3.824284091	3.864931398	3.549617387	3.716008122	3.095577609	3.109060959	2.890371758	2.944438979	3.63758616	3.666122467	3.784189634	3.660994251	0.78845736	2.24992244	2.664039858	1.085189268	1.190279477	0.970778917	2.00148	2.00148	0.904218151	1.62924054	1.767125188	1.686398954	0.587786665	1.704748092	1.704748092	1.481604541	1.487948015	1.90076334	1.410986974	1.252762968	1.252762968	1.321222364	1.064710737	1.410986974	0.832909123	0.832909123	1.111199404	2.87356464	2.151762203	0.875468737	-0.0010005	-0.510825624	1.335001067	1.30833282	2.87356464	3.117949906	3.117463062	2.151762203	1.064710737	0.693147181	0.832909123	1.344951398	1.344951398	-0.145025772	0.264669298	-0.105360516	-0.223143551	-0.140252673	-0.0010005	-0.049190244	-0.049190244	3.404366309	2.90690106	2.905205634	2.435628867	1.064710737	1.824549292	0.875468737	1.845268909	1.818076778	1.916922612	2.142298963	2.142298963	2.140066163	1.199362192	1.30833282	1.297463147	1.847630615	1.984856099	0.318453731	0.336472237	0.15956457	-0.533327912	2.575097262	3.218595786	3.218875825	2.494031558	2.406945108	3.173878459	2.57261223	0.78845736	2.734692132	1.264126727	1.826160896	1.919859472	0.732367894	0.724913496	0.979453307	0.848440065	0.670901572	0.670901572	0.670901572	0.693147181	1.872571112	1.379991892	2.330589289	1.903151757	1.903151757	1.902107526	1.166683064	1.634520693	0.655445313	1.435084525	1.429353851	1.429353851	0.771958361	2.742129199	3.141044005	0.88211328	0.709255394	2.12683032	1.717574571	1.30833282	1.372195437	1.064710737	1.516883931	1.146211903	2.28168209	2.324737898	1.081126974	2.424625719	0.867940471	0.951657876	1.722766598	1.252762968	1.252762968	1.547562509	0.985816795	1.280933845	1.270602887	0.444685821	1.589235205	0.771680735	1.568615918	1.064710737	1.064710737	1.098612289	1.100942904	1.160334347	0.78845736	1.1442228	0.993251773	0.587786665	0.587786665	2.178269289	0.92068108	1.539850893	2.421762081	2.202654254	3.248318115	2.360854001	2.272744251	1.759580571	2.00148	2.003100308	2.003100308	2.001885323	1.301008767	1.502965668	1.037091432	2.349188067	-0.702020761	2.648555273	2.151216064	2.048959494	0.547854808	0.770568195	0.114394447	1.112725724	0.226338442	0.226338442	1.499623046	1.512184434	1.449880192	0.661671649	-2.046503601	-2.038761829	0.899966257	0.461486637	0.126346635	1.380248228	1.510271584	0.423115157	0.61542736	0.628523297	1.000391629	0.591604392	0.518941185	0.684727936	-1.87763599	0.451916066	1.332909189	0.505217604	0.707999931	0.718432483	0.557890292	0.089854245	-0.266695454	0.090006177	0.217596316	0.148420005	0.145918203	-0.142126602	0.202802418	-0.133438468	0.350504733	0.183949945	1.940456298	1.065654254	0.14666507	0.089587233	0.381685842	0.203072688	0.368185268	-0.087018457	0.006409557	0.189721032	0.069112767	0.169699022	-0.13339559	1.52297359	0.608749011	-0.421009918	0.154330307	0.29006578	0.427334335	0.634064423	-0.322737763	2.547225561	2.587764035	2.933271592	2.933271592	3.36165339	3.525183361	3.434180734	2.807275688	2.824350657	2.061786606	3.097837496	3.308021589	3.308021589	1.742604886	-0.867500568	2.029857312	2.029857312	2.679606117	2.272125886	3.684462993	3.912013651	3.044921149	2.444703361	2.934593763	3.359333178	3.028247865	3.028247865	0.24455508	3.713944585	2.397131481	4.842900125	1.817420634	3.297027023	2.529621853	2.012115987	2.105818701	2.827805652	2.715551078	2.098080306	2.151178025	2.268634861	2.195455911	2.633234864	2.160078997	2.134514673	2.693212416	2.878483783	1.986338996	2.459013152	3.056595321	2.12724205	2.632798719	2.165800721	-1.360406662	2.275713815	2.142888251	2.338743956	2.57758361	2.058142738	3.033848178	0.771357067	1.852653312	1.798796585	2.908997551	3.12801224	2.498466375	2.146059256	2.98045045	3.097156417	2.884707205	2.102620434	2.713663862	3.011490396	2.103536735	2.90561085	2.103813316	2.447863423	2.247524903	1.978951251	2.512862292	2.780829799	2.019858819	2.925136652	2.291018451	2.961421957	2.21494257	2.45034186	1.887559018	2.209521487	1.982947863	1.880218521	1.455316955	2.243235499	2.16191549	1.919970791	1.602004828	1.930306738	1.765864971	2.410384783	2.619174373	2.1709614	1.773565712	2.778627683	2.669021578	2.124857929	2.221287068	2.073361492	2.066862759	2.29927019	3.061981064	2.14578692	2.382336613	2.154361755	2.475453713	2.246451982	2.483413521	1.970378272	2.696108592	2.52724749	2.655298019	2.926603096	2.011417142	2.335177459	2.484431458	2.450264192	2.034234961	2.176896293	2.52724749	2.192133723	2.055966922	2.917936038	1.393783447	0.838453827	1.642190281	2.28148415	2.349655807	2.257135197	1.801457781	1.520201791	2.10393205	1.758735485	2.196759887	2.271974724	2.050957794	1.929116843	1.860706862	2.230972302	2.129805466	1.357471196	2.24871235	1.251239847	1.86775208	2.178656565	2.071274362	1.994537485	2.490780687	-2.22186867	2.246805834	1.728257911	1.362600249	2.207608171	1.115362599	1.908059925	2.231733352	2.231733352	1.635521791	3.469796731	3.208421367];

%assignment of columns and rows
[inputs,Rows] = size(p);

%normalization between -1 and 1
[pn,ps] = mapminmax(p);
[tn,ts] = mapminmax(t);

%index creation for training, validation and test
p1 = 1:4:Rows;
p2 = 2:4:Rows;
p3 = 3:4:Rows;
p4 = 4:4:Rows;

%percentage assignment for: training(50%), validation(25%) and test(25%)
aa = [p2 p4];
vv = [p1];
tt = [p3];

%Creation of training, validation and test vectors
val.P = pn(:,vv); val.T = tn(:,vv);
test.P = pn(:,tt); test.T = tn(:,tt);
trainP = pn(:,aa); trainT = tn(:,aa);

%initial parameters
hiddenNeurons = 1;
maxHiddenNeurons = 20;
iterations = 15000;
targetIdeal = 0.99;
flagHiddenNeurons = 1;
learningRate = 0.01;
lrOption= 1 ;
rowOutputFile = 4;

%cycle that controls the number of hidden neurons
while(hiddenNeurons <= maxHiddenNeurons & flagHiddenNeurons == 1)

    %cycle that controls the learning rate (0.01, 0.001, 0.0001, 0.00001)
    while (lrOption <= 4)
        flagLearningRate = 1;
        rInitial = 0.1;        
        n = 1;       
        rCalculated = [];        
        
        %cycle that creates the ANN
        while (flagLearningRate == 1)
            net = newff(minmax(pn(:,aa)),[hiddenNeurons 1],{'tansig' 'purelin'},'trainlm');            
            net.trainParam.mu = learningRate;
            net.trainParam.epochs = 3000;
            net.trainParam.goal = 1e-6;
            
            [net,tr] = train(net,trainP,trainT,[],[],val,test);
            a = sim(net,pn);
            [m,b,r] = postreg(a,tn);          
            rCalculated(n) = r;                       
            
            if (r > rInitial)
                rInitial = r;
                slope = m;
                intercept = b;
                
                %denormalize output of the ANN
                for i=1:length(t)
                    outputANN(i) = ( ((a(i)+1)/2)*(max(t)-min(t)) )+min(t);                   
                end
                
                %calculate the RMSE
                for i=1:length(t)
                    tmpDifference(i)=(t(i)-outputANN(i));
                end
                tmp1=tmpDifference.^2;
                tmp2=sum(tmp1);
                rmse=sqrt(tmp2/length(t));               
                                    
                %Relative contribution - Garson algorithm 1991                
                contribution=[];
                c=[];
                R=[];
                S=[];                
               
                for mm=1:hiddenNeurons        
                    for k=1:inputs
                        c(mm,k)=net.IW{1,1}(mm,k)*net.LW{2,1}(1,mm);
                    end
                end                
               
                for mm=1:hiddenNeurons
                    for k=1:inputs
                        R(mm,k)=abs(c(mm,k))/(abs(c(mm,1))+abs(c(mm,2))+abs(c(mm,3))+abs(c(mm,4)));
                    end
                end
                
                %different cases for the number of hidden neurons                
                switch hiddenNeurons
                    case 1                        
                        for k=1:inputs
                            S(k)=R(1,k);
                        end
                    case 2                        
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k);
                        end
                    case 3                        
                        for k=1:inputs 
                            S(k)=R(1,k)+R(2,k)+R(3,k);
                        end
                    case 4                        
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k);
                        end                      
                    case 5                        
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k);
                        end
                    case 6
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k);
                        end
                    case 7
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k);
                        end
                    case 8
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k);
                        end
                    case 9
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k);
                        end
                    case 10
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k);
                        end
                    case 11
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k);
                        end
                    case 12
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k);
                        end
                    case 13
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k);
                        end
                    case 14
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k);
                        end
                    case 15
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k);
                        end                        
                    case 16
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k);
                        end
                    case 17
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k);
                        end
                    case 18
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k);
                        end
                    case 19
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k);
                        end
                    case 20
                        for k=1:inputs
                            S(k)=R(1,k)+R(2,k)+R(3,k)+R(4,k)+R(5,k)+R(6,k)+R(7,k)+R(8,k)+R(9,k)+R(10,k)+R(11,k)+R(12,k)+R(13,k)+R(14,k)+R(15,k)+R(16,k)+R(17,k)+R(18,k)+R(19,k)+R(20,k);
                        end                       
                    otherwise
                        disp('option not found')
                end
                
                % contribution of each input    
                for k=1:inputs
                    contribution(k)=S(k)/(S(1)+S(2)+S(3)+S(4));
                end
                
                %saving weights of the ANN in txt files
                bestIteration=n;
                IW=net.IW{1,1};
                lw=net.LW{2,1};
                LW=lw';
                b1=net.b{1};
                b2=net.b{2};                
                filename1 = [num2str(hiddenNeurons),'_neurons_lr_',num2str(learningRate),'_IW','.txt'];
                filename2 = [num2str(hiddenNeurons),'_neurons_lr_',num2str(learningRate),'_b1','.txt'];
                filename3 = [num2str(hiddenNeurons),'_neurons_lr_',num2str(learningRate),'_LW','.txt'];
                filename4 = [num2str(hiddenNeurons),'_neurons_lr_',num2str(learningRate),'_b2','.txt'];              
                save(filename1,'IW','-ascii');
                save(filename2,'b1','-ascii');
                save(filename3,'LW','-ascii');
                save(filename4,'b2','-ascii');                
     
            end %end of if (r > rInitial)
            
            %if the ideal target is reached or all the iterations are executed
            if (r >= targetIdeal || n == iterations)
              flagLearningRate = 0;
            else              
              n = n+1
            end
        
        end % end of while (flagLearningRate == 1)
        
        %for report in txt
        rMax = max(rCalculated);
        rMin = min(rCalculated);
        rSort = sort(rCalculated);
        rMedian = median(rSort);        
        input1 = contribution(1);
        input2 = contribution(2);
        input3 = contribution(3);
        input4 = contribution(4);
       
        %creation of results vector
        results = [inputs, hiddenNeurons, iterations, learningRate, rMin, rMedian, rMax, rmse, slope, intercept, input1, input2, input3, input4, bestIteration];
        
        %save in file txt        
        dlmwrite('report_output_ANN30.txt',results,'-append','delimiter',',','newline','unix');
        results = [];
                
        %different cases for learning rate
        switch(lrOption)
            case 1
                learningRate = 0.001;
                lrOption = lrOption+1;                
            case 2
                learningRate = 0.0001;
                lrOption = lrOption+1;
            case 3
                learningRate = 0.00001;
                lrOption = lrOption+1;
            case 4
                lrOption = lrOption+1;
            otherwise
                disp('option not found')
        end %end switch(lrOption)           
        
    end %end of while (lrOption <= 4)
    
    %we reset parameters for the next hidden neuron
    hiddenNeurons = hiddenNeurons+1;
    lrOption = 1;
    learningRate = 0.01;

end %end of while(hiddenNeurons <= maxHiddenNeurons & flagHiddenNeurons == 1)
